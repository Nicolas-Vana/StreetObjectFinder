{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "# from sklearn.cluster import DBSCAN\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def segment_points(gdf, distance_threshold):\n",
    "    # Convert the GeoDataFrame to a numpy array\n",
    "    points = np.array([[geom.y, geom.x] for geom in gdf.geometry])\n",
    "\n",
    "    # Initialize DBSCAN with the distance threshold\n",
    "    dbscan = DBSCAN(eps=distance_threshold, min_samples=1, algorithm='ball_tree', metric='haversine')\n",
    "\n",
    "    # Fit the DBSCAN model to the points\n",
    "    clusters = dbscan.fit_predict(points)\n",
    "\n",
    "    # Create a new GeoDataFrame with the clustered points\n",
    "    gdf['cluster'] = clusters\n",
    "    return gdf['cluster']\n",
    "\n",
    "def distribute_clusters_into_groups(gdf, n_groups):\n",
    "    \"\"\"\n",
    "    Distributes clusters into groups, ensuring each cluster is entirely contained within\n",
    "    a single group and aiming for a similar number of rows in each group.\n",
    "    \n",
    "    Parameters:\n",
    "    - gdf: GeoDataFrame that includes a 'cluster' column.\n",
    "    - n_groups: The number of groups to distribute the clusters into.\n",
    "    \n",
    "    Returns:\n",
    "    - A copy of the gdf with an additional column 'group' indicating the group assignment.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate cluster sizes\n",
    "    cluster_sizes = gdf['cluster'].value_counts().reset_index()\n",
    "    cluster_sizes.columns = ['cluster', 'size']\n",
    "    \n",
    "    # Sort clusters by size in descending order\n",
    "    cluster_sizes = cluster_sizes.sort_values(by='size', ascending=False)\n",
    "    \n",
    "    # Initialize groups\n",
    "    groups = {i: [] for i in range(n_groups)}  # Dictionary to hold cluster IDs for each group\n",
    "    group_sizes = {i: 0 for i in range(n_groups)}  # Dictionary to track the total size of each group\n",
    "    \n",
    "    # Distribute clusters into groups\n",
    "    for _, row in cluster_sizes.iterrows():\n",
    "        cluster_id, size = row['cluster'], row['size']\n",
    "        \n",
    "        # Find the group with the minimum size\n",
    "        min_group = min(group_sizes, key=group_sizes.get)\n",
    "        \n",
    "        # Assign the cluster to this group\n",
    "        groups[min_group].append(cluster_id)\n",
    "        group_sizes[min_group] += size\n",
    "    \n",
    "    # Map clusters to their assigned group\n",
    "    cluster_to_group = {cluster: group for group, clusters in groups.items() for cluster in clusters}\n",
    "    gdf['group'] = gdf['cluster'].map(cluster_to_group)\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "def fetch_most_recent_results(target_folder, prefix='*'):\n",
    "    search_pattern = os.path.join(target_folder, f\"{prefix}_*.pkl\")\n",
    "\n",
    "    # Find all files matching the pattern\n",
    "    files = glob.glob(search_pattern)\n",
    "\n",
    "    if len(files) == 0:\n",
    "        return 'None'\n",
    "\n",
    "    # Extract numbers from the filenames and find the max\n",
    "    max_file = None\n",
    "    max_num = -1\n",
    "    for file in files:\n",
    "        try:\n",
    "            # Extract the number from the filename\n",
    "            num = int(os.path.basename(file).split('_')[-1].split('.')[0])\n",
    "            if num > max_num:\n",
    "                max_num = num\n",
    "                max_file = file\n",
    "        except ValueError:\n",
    "            # Skip files where the number cannot be parsed\n",
    "            continue\n",
    "\n",
    "    return max_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_csv('./assets/examples/sample_curitiba.csv')\n",
    "selected['geometry'] = gpd.points_from_xy(x=selected['LONGITUDE'], y=selected['LATITUDE'])\n",
    "selected = selected.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location distribution between groups [3]\n",
      "spinning up 1 processess\n",
      "Params passed to Resize transform:\n",
      "\twidth:  640\n",
      "\theight:  640\n",
      "\tresize_target:  True\n",
      "\tkeep_aspect_ratio:  False\n",
      "\tensure_multiple_of:  14\n",
      "\tresize_method:  minimal\n",
      "Using pretrained resource local::./checkpoints/depth_anything_metric_depth_outdoor.pt\n",
      "Loaded successfully\n"
     ]
    }
   ],
   "source": [
    "selected['cluster'] = segment_points(selected, 0.00009*20)\n",
    "\n",
    "num_groups = 3\n",
    "grouped = distribute_clusters_into_groups(selected, num_groups)\n",
    "location_distribution = grouped['group'].value_counts().values.tolist()\n",
    "\n",
    "print(f\"Location distribution between groups {location_distribution}\")\n",
    "if len(location_distribution) < num_groups:\n",
    "    num_groups = len(location_distribution)\n",
    "\n",
    "os.makedirs('./tmp_inputs', exist_ok=True)\n",
    "\n",
    "for group in grouped['group'].unique():\n",
    "    subset = grouped[grouped['group'] == group]\n",
    "    subset = subset.head(1000)\n",
    "    \n",
    "    subset.drop(columns='geometry').to_csv(f'./tmp_inputs/group_{str(group)}.csv')\n",
    "\n",
    "def run_script(file_path, target_path, world_path):\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"main.py\", file_path, target_path, world_path], check=True)\n",
    "\n",
    "target_path = './world_models/sample_curitiba'\n",
    "target_paths = [target_path] * num_groups\n",
    "world_path = [fetch_most_recent_results(target_path, 'consolidated')] * num_groups\n",
    "print(f'spinning up {num_groups} processess')\n",
    "\n",
    "# Run the script in parallel for each file\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    file_paths = [f'./tmp_inputs/group_{str(group)}.csv' for group in range(num_groups)]\n",
    "    executor.map(run_script, file_paths, target_paths, world_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./world_models/backbone_v2/intermediary_savestates/group_0_65.pkl', './world_models/backbone_v2/intermediary_savestates/group_1_65.pkl', './world_models/backbone_v2/intermediary_savestates/group_2_64.pkl']\n"
     ]
    }
   ],
   "source": [
    "from core.world import World\n",
    "import copy\n",
    "import os\n",
    "\n",
    "def get_latest_group_files(num_groups, folder_name):\n",
    "\t\"\"\"\n",
    "\tReturn a list of paths for the highest version number file for each group within the specified folder.\n",
    "\n",
    "\tParameters:\n",
    "\t\tnum_groups (int): Number of groups to process.\n",
    "\t\tfolder_name (str): Folder containing the group files.\n",
    "\n",
    "\tReturns:\n",
    "\t\tlist of str: Paths to the files with the highest version number for each group.\n",
    "\t\"\"\"\n",
    "\t# Dictionary to keep track of the highest version file for each group\n",
    "\tlatest_files = {}\n",
    "\n",
    "\t# List all files in the given folder\n",
    "\tfor file in os.listdir(folder_name):\n",
    "\t\tif file.startswith(\"group_\") and file.endswith(\".pkl\"):\n",
    "\t\t\t# Extract group number and version number from the filename\n",
    "\t\t\t_, group_number, version = file.split(\"_\")\n",
    "\t\t\tversion = version.split(\".\")[0]  # Remove the file extension\n",
    "\n",
    "\t\t\t# Convert extracted values to integers\n",
    "\t\t\tgroup_number = int(group_number)\n",
    "\t\t\tversion = int(version)\n",
    "\n",
    "\t\t\t# Update the dictionary if this is the highest version for the group\n",
    "\t\t\tif group_number not in latest_files or version > latest_files[group_number][1]:\n",
    "\t\t\t\tlatest_files[group_number] = (file, version)\n",
    "\n",
    "\t# Generate the final list of file paths, sorted by group number\n",
    "\tsorted_files = [os.path.join(folder_name, latest_files[group_number][0]) \n",
    "\t\t\t\t\tfor group_number in sorted(latest_files) \n",
    "\t\t\t\t\tif group_number < num_groups]\n",
    "\n",
    "\treturn sorted_files\n",
    "\n",
    "folder_name = f'{target_path}/intermediary_savestates'\n",
    "num_groups = 3\n",
    "files = get_latest_group_files(num_groups, folder_name)\n",
    "print(files)\n",
    "\n",
    "savestates = []\n",
    "gdfs = []\n",
    "buffered_gdfs = []\n",
    "locations = []\n",
    "tmp_world = World()\n",
    "\n",
    "for file in files:\n",
    "    tmp_world.loadstate(file)\n",
    "    savestates.append(copy.deepcopy(tmp_world))\n",
    "\n",
    "for world in savestates:\n",
    "    gdfs.append(world.gdf)\n",
    "    buffered_gdfs.append(world.buffered_geometries)\n",
    "    locations.append(world.locations)\n",
    "\n",
    "final_gdf = pd.concat(gdfs)\n",
    "final_buffered = pd.concat(buffered_gdfs)\n",
    "final_locations = [item for sublist in locations for item in sublist]\n",
    "\n",
    "final_world = World()\n",
    "final_world.gdf = final_gdf\n",
    "final_world.buffered_geometries = final_buffered\n",
    "# final_world.locations = final_locations\n",
    "\n",
    "for location in final_locations:\n",
    "\tfinal_world.add_Location360(location.lat, location.lon, obj=location)\n",
    "\n",
    "final_world.buffer_distance = tmp_world.buffer_distance\n",
    "\n",
    "visited = [index for index, location in enumerate(final_world.locations) if location.walked == True]\n",
    "final_world.savestate(f'{target_path}/consolidated_{len(visited)}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<core.world.World at 0x7f31d5797690>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core.world import World\n",
    "world = World()\n",
    "world.loadstate(f'{target_path}/consolidated_1997.pkl')\n",
    "world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_config = {'version': 'v1',\n",
    " 'config': {'visState': {'filters': [{'dataId': ['objects'],\n",
    "     'id': 'o3yn4nfz',\n",
    "     'name': ['target'],\n",
    "     'type': 'select',\n",
    "     'value': True,\n",
    "     'enlarged': False,\n",
    "     'plotType': 'histogram',\n",
    "     'animationWindow': 'free',\n",
    "     'yAxis': None,\n",
    "     'speed': 1},\n",
    "    {'dataId': ['objects'],\n",
    "     'id': 'ieifk7u9d',\n",
    "     'name': ['image_type'],\n",
    "     'type': 'multiSelect',\n",
    "     'value': ['final_step'],\n",
    "     'enlarged': False,\n",
    "     'plotType': 'histogram',\n",
    "     'animationWindow': 'free',\n",
    "     'yAxis': None,\n",
    "     'speed': 1}],\n",
    "   'layers': [{'id': 'oyar70g',\n",
    "     'type': 'geojson',\n",
    "     'config': {'dataId': 'objects',\n",
    "      'label': 'objects',\n",
    "      'color': [41, 76, 181],\n",
    "      'highlightColor': [252, 242, 26, 255],\n",
    "      'columns': {'geojson': 'geometry'},\n",
    "      'isVisible': True,\n",
    "      'visConfig': {'opacity': 0.5,\n",
    "       'strokeOpacity': 0.8,\n",
    "       'thickness': 2.5,\n",
    "       'strokeColor': None,\n",
    "       'colorRange': {'name': 'ColorBrewer Dark2-7',\n",
    "        'type': 'qualitative',\n",
    "        'category': 'ColorBrewer',\n",
    "        'colors': ['#1b9e77',\n",
    "         '#d95f02',\n",
    "         '#7570b3',\n",
    "         '#e7298a',\n",
    "         '#66a61e',\n",
    "         '#e6ab02',\n",
    "         '#a6761d']},\n",
    "       'strokeColorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'radius': 10,\n",
    "       'sizeRange': [0, 10],\n",
    "       'radiusRange': [0, 50],\n",
    "       'heightRange': [0, 500],\n",
    "       'elevationScale': 5,\n",
    "       'enableElevationZoomFactor': True,\n",
    "       'stroked': False,\n",
    "       'filled': True,\n",
    "       'enable3d': False,\n",
    "       'wireframe': False},\n",
    "      'hidden': False,\n",
    "      'textLabel': [{'field': None,\n",
    "        'color': [255, 255, 255],\n",
    "        'size': 18,\n",
    "        'offset': [0, 0],\n",
    "        'anchor': 'start',\n",
    "        'alignment': 'center'}]},\n",
    "     'visualChannels': {'colorField': {'name': 'obj_type', 'type': 'integer'},\n",
    "      'colorScale': 'quantize',\n",
    "      'strokeColorField': None,\n",
    "      'strokeColorScale': 'quantile',\n",
    "      'sizeField': None,\n",
    "      'sizeScale': 'linear',\n",
    "      'heightField': None,\n",
    "      'heightScale': 'linear',\n",
    "      'radiusField': None,\n",
    "      'radiusScale': 'linear'}},\n",
    "    {'id': 'ittjroo',\n",
    "     'type': 'geojson',\n",
    "     'config': {'dataId': 'Postes Vtal',\n",
    "      'label': 'Postes Vtal',\n",
    "      'color': [210, 0, 0],\n",
    "      'highlightColor': [252, 242, 26, 255],\n",
    "      'columns': {'geojson': 'geometry'},\n",
    "      'isVisible': True,\n",
    "      'visConfig': {'opacity': 0.5,\n",
    "       'strokeOpacity': 0.8,\n",
    "       'thickness': 0.5,\n",
    "       'strokeColor': None,\n",
    "       'colorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'strokeColorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'radius': 10,\n",
    "       'sizeRange': [0, 10],\n",
    "       'radiusRange': [0, 50],\n",
    "       'heightRange': [0, 500],\n",
    "       'elevationScale': 5,\n",
    "       'enableElevationZoomFactor': True,\n",
    "       'stroked': False,\n",
    "       'filled': True,\n",
    "       'enable3d': False,\n",
    "       'wireframe': False},\n",
    "      'hidden': False,\n",
    "      'textLabel': [{'field': None,\n",
    "        'color': [255, 255, 255],\n",
    "        'size': 18,\n",
    "        'offset': [0, 0],\n",
    "        'anchor': 'start',\n",
    "        'alignment': 'center'}]},\n",
    "     'visualChannels': {'colorField': None,\n",
    "      'colorScale': 'quantile',\n",
    "      'strokeColorField': None,\n",
    "      'strokeColorScale': 'quantile',\n",
    "      'sizeField': None,\n",
    "      'sizeScale': 'linear',\n",
    "      'heightField': None,\n",
    "      'heightScale': 'linear',\n",
    "      'radiusField': None,\n",
    "      'radiusScale': 'linear'}}],\n",
    "   'interactionConfig': {'tooltip': {'fieldsToShow': {'objects': [{'name': 'id',\n",
    "        'format': None},\n",
    "       {'name': 'distance', 'format': None},\n",
    "       {'name': 'image_type', 'format': None},\n",
    "       {'name': 'target', 'format': None}],\n",
    "      'Postes Vtal': [{'name': 'Name', 'format': None},\n",
    "       {'name': 'descriptio', 'format': None},\n",
    "       {'name': 'timestamp', 'format': None},\n",
    "       {'name': 'begin', 'format': None},\n",
    "       {'name': 'end', 'format': None}],\n",
    "      'Starters': [{'name': 'LATITUDE', 'format': None},\n",
    "       {'name': 'LONGITUDE', 'format': None}]},\n",
    "     'compareMode': False,\n",
    "     'compareType': 'absolute',\n",
    "     'enabled': True},\n",
    "    'brush': {'size': 0.5, 'enabled': False},\n",
    "    'geocoder': {'enabled': False},\n",
    "    'coordinate': {'enabled': False}},\n",
    "   'layerBlending': 'normal',\n",
    "   'splitMaps': [],\n",
    "   'animationConfig': {'currentTime': None, 'speed': 1}},\n",
    "  'mapState': {'bearing': 0,\n",
    "   'dragRotate': False,\n",
    "   'latitude': -25.437284343802318,\n",
    "   'longitude': -49.306400994975846,\n",
    "   'pitch': 0,\n",
    "   'zoom': 16.19470706392811,\n",
    "   'isSplit': False},\n",
    "  'mapStyle': {'styleType': 'dark',\n",
    "   'topLayerGroups': {},\n",
    "   'visibleLayerGroups': {'label': True,\n",
    "    'road': True,\n",
    "    'border': False,\n",
    "    'building': True,\n",
    "    'water': True,\n",
    "    'land': True,\n",
    "    '3d building': False},\n",
    "   'threeDBuildingColor': [9.665468314072013,\n",
    "    17.18305478057247,\n",
    "    31.1442867897876],\n",
    "   'mapStyles': {}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl import KeplerGl\n",
    "\n",
    "def plot_objects(world, map_=None, config=None):\n",
    "        if not map_:\n",
    "            map_ = KeplerGl(height=600)\n",
    "\n",
    "        tmp_df = world.gdf.copy()\n",
    "        map_.add_data(data=tmp_df.drop(columns=['obj', 'image', 'starter']), name='objects')\n",
    "\n",
    "        if config:\n",
    "            map_.config = config\n",
    "\n",
    "        return map_\n",
    "\n",
    "world_map = plot_objects(world, config=world_config) # config=world_config\n",
    "world_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
